{
  "1": {
    "id": "1",
    "title": "",
    "content": "Failed FW Update, Factory Reset… The Solo has inside two SD Cards, one for the flight controller and one for the system. A factory reset or a firmware update can go wrong due to a write error on the SD card of the Controller or the card inside Solo. Usually the SD card is damaged and useless afterwards. This would be no problem if only one could take the SD card and push a new image on it. But first you have to tear down the whole Solo hardware including the flight controller. Second you have to cut the glued SD card which is a fairly fumbling job and finally you nee the images for flashing the two SD cards. Just to complete this weird story: You are loosing all warranties and there was know help ever from the 3DR team. If you have disassembled the Solo you just need to push the images on a new SD card and reassable the whole thing. Assuming you have the downloaded image at ‘’~/proj/drone/3DR/image/’’ and it is named ‘‘mmcblk0_Solo’’ you can easily push it to the SD Card with the following command. &lt;code:bash&gt; Solo image (SD Card from the flight controller of the Solo) sudo dd if=~/proj/drone/3DR/image/mmcblk0_Solo of=/dev/mmcblk0 controller image (SD card from the ardoo RC controller) sudo dd if=~/proj/drone/3DR/image/mmcblk0 of=/dev/mmcblk0 &lt;/code&gt; In most cases you need to fix the flight controller of the Solo. When you repair the connection manually you may avoid disassembling the Artoo controller and just fix one image. For getting the images and more information you have to contact the Facebook Group 3DR Solo Hack or contact — //Christoph Reudenbach//",
    "url": "http://localhost:4000/giswerk.org/docs/rs/micrors/uavrs/3drsolo/crash/",
    "relUrl": "/docs/rs/micrors/uavrs/3drsolo/crash/"
  },
  "2": {
    "id": "2",
    "title": "",
    "content": "DJI Flight Planning Tutorial Introduction The flightplanning cookbook is addressing the utilisation of ready to fly (rtf) unmanned aerial vehicles (uav) for remote sensing purposes. The basic idea is to use rtf-uavs for advanced high resolution data retrievals. The range is widespread from Digital Surface Models (DSM), Digital Elevation Models (DEM), orthophotos, altitude point clouds to landuse/landscape classification, NDVI forest structure classifications and so on… This document will cover in brief the recipe to solve the all day problems of typical survey planning. A deeper discussion and knowledge base is provided at the micro remote sensing (mRS) wiki. Overview of the task This recipe deals with the effective and safe planning of an autonomous flight. This covers necessary hardware and software as well as supplemental data and nice to haves. Skills you will learn In the extended version you find some more explanations and hints for improving your planning. Even if you can assume the use of uavs for Remote Sensing (RS) purposes as “operational” you should always keep in mind that avoiding negative impacts is a result of ￼responsible and focused planning. &lt;note warning&gt;Please keep in mind that autonomous uavs are dangerous for the environment as well as you easily can loss or damage them. &lt;/note&gt; Things you need R (examples are in RStudio) Robubu package Digital Elevation Model data (depending on the area DJI Phantom 3 (P3) Advanced/Professional Litchi Flight App / Tower App Time to work it out The Whys Why R Easy to use and well known in the environmental research community. R is pretty flexible and there exist a lot of post processing and classification algorithm to head on after the flight planning. It seems to be (beside Python) the best approach to reach the people interested in mRS and to keep out the drone dudes ;-). Why Phantom? 4k camera, easy to fly, cheap, fast, robust and fairly reliable to control. Why Litchi? The main problem with DJI-stuff is that these guys control **everything **via their cloud which is obligate to use. Besides this kind of “political” impacts there does not exist an interface for pushing waypoint data for autonomous flights to the P3 without using their cloud. The third party software Litchi provides an interface to the DJI uav family implemented as a webtool for conversion and upload of user generated csv/kml control files to the P3. Flight planning The planning of survey flights is depending on some constraints that will be discussed elsewhere. However for now some bullet points should be mentioned: weather topography usage/protection state of the area unknown physical obstacles (UPOs) technical restrictions of the uav-platform safety issues (backup flight control, parachute, GPS tracker) General Workflow Identify the area, digitize/type the coords of 3 corners and the launching position Adjust the flight parameters to your needs and generate flight control files Convert and upload the mission control files either directly to your tablet/smartphone or alternatively via the Litchi cloud. Make an extensive preflight check Fly the mission Installation It is assumed that you are familiar with the R platform. Just go ahead and install the robubu package from github using the devtools package. &lt;Code:R&gt; devtools::install_github(“gisma/robubu”,ref=”master”) &lt;/Code&gt; If you want to install all dependencies use: &lt;Code:R&gt; devtools::install_github(“gisma/robubu”,ref=”master”, dependencies = TRUE, force = TRUE) &lt;/Code&gt; Note it is strongly recommended that you use a Linux platform. Nevertheless windows will probably work but Mac is not tested and won’t work most probably. Additionally to R you must have installed at least GDAL SAGA GIS and GRASS GIS. For further information please refer to the Open Source GIS installation support pages. ## Training examples ===== The first example will introduce you to the basic usage and folder structure. Basic Example Phantom 3 Purpose: Survey flight over flat terrain to generate DSM and orthophoto. It is described for the Phantom3 and Litchi only. Addressed issues: Create a reliable DSM for near surface retrieval of high resolution pictures Create an orthophoto for visual inspection of POIs The short way Digitize the 3 corner points of an area you want to map and in addition as fourth point the position of the planned uav launch. Save it to firstSurvey.json. &lt;Code:R&gt; library(robubu) # preset = “uav” supress all not necessary tools leafDraw(mapCenter = c(50.855,8.691),preset=”uav”) # Use the digitized data and the example DEM to calculate a flight control file fp&lt;-makeFP(rootDir=”~/proj”, workingDir=”/drone/firstSurvey”, missionName =”valleyWood”, surveyArea=”firstSurvey.json”, flightAltitude =100, demFn = data(mrbiko)) &lt;/Code&gt; Note: The first two points determine the flight angle and direction the second and third coordinate determine the width of the area. If you want so save it on your SD card, open the Litchi Mission website and click on the button ‘‘Missions-&gt;Import’’. Next navigate to the control file ‘‘firstsurvey_1001.csv’’ (you’ll find it in the folder ‘’~/projectDir/mission/control’’). For exporting it choose ‘‘Missions-&gt;Save’’ and navigate/upload it to your missions subfolder of the Litchi app. That’s it. Even more simple is the option to connect with the litchi cloud. While you are logged in with the same account it is synchronizing the data as soon as you start the litchi app. The long way Digitizing of the survey area We want to plan a flight in a more or less flat terrain in the upper Lahn-valley. First load the libraries and next start the small digitizing tool that is provided in ‘‘robubu’’. Note: you may take any other tool to digitize the survey area as well as you may type the coordinates on Stdin. &lt;Code:R&gt; load robubu library(robubu) start digitizing tool with preset = “uav” for a reduced toolbar see ?leafDraw for more information leafDraw(mapCenter = c(50.855,8.691),preset=”uav”) &lt;/Code&gt; Feel free to digitize the four points needed: P1,P2,P3 define the extend and angles of the mission area. P1 is the starting point of the survey Flight direction angle and along distance is defined by P1-&gt;P2 P2-&gt;P3 defines the cross distance P4 is the launching point. Try to digitize it very carefully because of getting an optimal launch altitude. Some planning hints If possible put the launching position somewhere (assumingly in the middle) of the proposed survey area with respect to a optimal visibility to the uav and the shortest possible distance for the radio controller to keep in contact to the uav. It is helpful to fly along structures with the climbs at the end of each track. It save energy and in most cases the climbs can be visually controlled easier. Try to identify your launching point//** very carefully// and// most reliable**//. The Phantom is taking this position as a home (reference) point for both position and altitude. Finish digitizing and save it either as JS =JSON or KML file. Take care to use the correct extensions ‘‘.json’’ or ‘‘.kml’’ (the ‘‘makeFP()’’ function is requiring the correct extension). In the current example save it as a json file named ‘‘firstSurvey.json’’. Calling makeFP Working directories and other structural defaults There are a lot of params to control the generation of an autonomous flight plan. In this first use case we keep it according to the issues of the task as simple as possible. First you some convenient params to organize the project as the project folder called ‘’~/proj/uav’’ which is stored in ‘‘projectDir’’. The current working directory will be generated from the mission name and is always a subfolder of the ‘‘projectDir’’. So in this case it is set to ‘‘firstSurvey’’. you will find in the resulting mission folder named ‘’~/proj/uav/firstsurvey’’ two more subfolders. One is named ‘‘control’’ (for all control and log files) and the other is called ‘‘run’’ for all run time files that are generated during the analysis process. Please note: additionally all used data files are copied to a folder called ‘‘data’’, which is located directly under the ‘‘projectDir’’ folder. The project structure will look like the figure. Arguments used &#39;’flightAltitude’’ is set to the (legal) maximum of 100 m, ‘‘flightPlanMode’’ is set to ‘‘track’’ and finally a DEM of this area with 20m resulution is used to retrieve the altitude of the launching point. If we use the example data we first have to convert them to a valid GeoTiff file. &lt;Code:R&gt; data(mrbiko) # to use the example data it’s easier to write same in tif format writeRaster(mrbiko,”~/dem.tif”) fp&lt;-makeFP(projectDir =”~/uav/cookbook”, missionName =”firstSurvey”, surveyArea=”~/proj/drone/uniwald/myFirstSurvey.json”, flightAltitude =100, maxSpeed =35, demFn =”~/dem.tif”) &lt;/Code&gt; The script generates: R objects for visualisation log file flight control file(s). All three of them are important even if a quick inspection of the generated objects is most of the time sufficient. The log file dump summarize the most import params, as the calculated speed and picture rate based on an estimation of the mission time. In general you can say as higher you fly as faster you can go. The flight time will significantly increase with each 10 meter lowering the flight altitude. &lt;Code:bash&gt; [1]”[ 2016-09-26 23:17:26 ] INFO —– use the following mission params! ——- “ [1]”[ 2016-09-26 23:17:26 ] INFO set RTH flight altitude to : 100 (m) “ [1]”[ 2016-09-26 23:17:26 ] INFO set mission speed to a max of: 35 (km/h) “ [1]”[ 2016-09-26 23:17:26 ] INFO set pic rate to at least : 5.3 (sec/pic) “ [1]”[ 2016-09-26 23:17:26 ] INFO calculated mission time : 12.2 (min) “ [1]”[ 2016-09-26 23:17:26 ] INFO estimated battery liftime : 10 (min) “ [1]”[ 2016-09-26 23:17:26 ] INFO Area covered : 37.2799964578867 (ha) “ NOTE 1: flighttime &gt; battery lifetime! control files have been splitted.HaveFun… NOTE 2:You will find all parameters in the logfile:~/uav/cookbook/firstSurvey/control/firstSurvey_100.log &lt;/Code&gt; Using ‘‘mapview()’’ you can easily visualize the result. You see the footprints of the images (blue), surveyArea(red), turnpoints of track (blue circles), launch position (red). &lt;Code:R&gt; mapview(fp5,color=”red”, alpha.regions =0.1,lwd=0.5)+ mapview(fp1,zcol =”altitude”,lwd=1,cex=4)+ mapview(fp3,color=”red”,cex=5)+ mapview(fp4,color=”darkblue”, alpha.regions =0.1,lwd=0.5) &lt;/Code&gt; Just for your interest the resulting basic control file is named ‘‘firstSurvey_1001.csv’’ and looks (DJI) like this: &lt;Code:R&gt; latitude,longitude,altitude,heading,curvesize,rotationdir,gimbalmode,gimbalpitchangle,actiontype1 50.8562700012854,8.67969274520874,100,61.3278866905878,0,0,0,-90,0.6 50.8562397243629,8.67955902673377,100,61.3278866905878,0,0,0,-90,0.6 50.854739330123,8.67293357849121,100,61.3278866905878,0,0,0,-90,0.6 50.854739330123,8.67293357849121,100,61.3278866905878,0,0,0,-90,0.6 50.8550343329483,8.67378583665562,100,61.3278866905878,0,0,0,-90,0.6 50.8553293357587,8.67463810019652,100,61.3278866905878,0,0,0,-90,0.6 50.855624338554,8.67549036911401,100,61.3278866905878,0,0,0,-90,0.6 50.8559193413343,8.67634264340815,100,61.3278866905878,0,0,0,-90,0.6 50.8562143440996,8.67719492307906,100,61.3278866905878,0,0,0,-90,0.6 &lt;/Code&gt; If you ever forget what you did you will find a log file with the whole logging history of the mission called ‘‘firstSurvey_100’’ in the ‘‘control’’ directory. Export to the flight app Open Litchi Mission and click on the button ‘‘Missions-&gt;Import’’ and navigate to the control file firstSurvey_1001.csv. To export it click ‘‘Missions-&gt;Save’’. If you need to export the files offline you can use this workaround. Ready to take off - that’s the first flight plan.",
    "url": "http://localhost:4000/giswerk.org/docs/rs/micrors/uavrs/dji/djimakefp/",
    "relUrl": "/docs/rs/micrors/uavrs/dji/djimakefp/"
  },
  "3": {
    "id": "3",
    "title": "",
    "content": "Postprocessing UAV Footage This documents provides a basic workflow of the georeferencing process of Solo/Pixhawk flight data as well as the optimized workflow for deriving high quality point clouds 3D models and orthoimages. In detail it covers the topics: data acquisition constraints geotagging of the images high quality image alignment high quality point cloud generation high quality orthoimages generation high quality dense point clouds importing and exporting data from photoscan Agisoft Photoscan scripting interaction with the uavRst package &lt;note tip&gt;This is a preliminary draft. Please note that significant changes can still be expected&lt;/note&gt; Constraints of data acquisition The base for good micro-remote sensing products are the images takes by the drone. They will pass through a post processing workflow where the original picture quality determines the quality in every further step. It is pretty simple and successful if one keep in mind some very basic constraints during data acquisition. Actually you should take care of two requirements: sufficient overlap, provide photos where at least 70% of the photo is on focus while avoiding scale leaps (surface following flight paths). Consider on which footprint the overlap is calculated. If you have different structure layers in different distances to the camera, the overlap differs for every of this layers as they have all their own footprint dimensions. diffuse but bright light, best is at noon with kind of high thin cirrus clouds scattering the light perfectly and reduce shadows…. Prerequisites The following workflow requires some tools: You need themapillary_toolswhich is a very useful bunch of python scripts dealing with image placement on web maps. To run them you also need to install ‘‘gpxpy’’, ‘‘pillow’’, ‘‘exifread’’,’‘pyexiv2’’ . If running windows please install first a pip installer derivative, running Linux you can install pip with ‘‘sudo apt-get install pip’’. Then you may install the dependencies like following: :::bash pip install git+[[https://github.com/mapillary/mapillary_tools.git|https://github.com/mapillary/mapillary_tools.git]] pip install gpxpy pip install exifread pip install Pillow sudo apt-get install python-pyexiv2 (Linux) For Windows you will find at launchpad pyexif2. Next (if not already installed) you need to install the gpsbabel binaries. :::bash sudo apt-get install gpsbabel For the visualization of the gpx data you may use QGIS or mapview and plotRGB in R. Adding geotags to the images Almost no standalone camera has a GPS *or an *aGPS onboard. As a result no image will have a spatial reference at all. Georeferenced images can be aligned better and faster and, as a side effect, one will have a fairly good georeference (~1-5 meters). So even if this task is a bit cumbersome it will help a lot. The most prominent way to apply a spatial position is to add geotags to the images. This needs a semi-automated post processing. The best software doing so is geosetter, which is unfortunately not running very stable under Linux and OSX (besides some other shortcomings). Actually, while adding geotags you have to deal with three effects: time shift between logger and camera time automatic timezone adaption of the data identification of a start and stop image within the time series For our needs we want to align the images along the flight track within a accuracy of 2-5 seconds (according to lapse rate). It seems to be kind of senseless to automate this process due to the fact that you always have to start and stop the cameras manually and you always will take pictures on the ascending, descending going to and coming back from the core task. | Note: You have to find out when the timestamp of the image is created. Shooting the picture or saving the file (what might be a few seconds later, e.g. for Mapir-cameras the timestamp is created in that moment the file is saved). | | ————————————————————————————————————————————————————————————————————————————– | Preparation of the data If not done you need to organize some basic things. It is more than helpful to separate each partial flight an the corresponding gpx file in a subdirectory. Very straightforward it may look like below. separate all image files according to the corresponding flight (log file) copy the GPX-log file into the same directory The basic concept You have to find the start and stop image of the partial task. Load the task in QGIS open the Bing aerial map and the first and last image. In most cases you can easily identify the rough position of the camera. It is by no means necessary to get an extremely exact result. You just need to to generate a correct sequence according to the gpx track points as described below. The workflow Open a terminal and navigate to the image/gpx folder. Write fake exif date and time tag :::bash python~/dev/R/uavRst/inst/python/add_fix_dates.py.&#39;2017-05-16 16:44:12&#39;**2** &lt;note important&gt;Please note: - the location of the scripts is arbitrary - you start with the best fitting track point according to your first image - the dot is obligatory to point to the actual directory - the 2 is the time increment of the cameras lapse rate in seconds - take the time of the GPX-time-tag (red 16)real GPS time is 14 &lt;/note&gt; Cut the gpx log file :::bash gpsbabel-t -i gpx -f current_solo.gpxtrack, start=20170516144408,stop=20170516144930-o gpx-F clean_task.gpx &lt;note important&gt; Please note: gpsbabel may re-interpret the time tag to GPS time so usually you have to set the time shifted by the time zone and summertime just add for convenience two lapse rate steps in the beginning and end Write the derived geotags to each image file. &lt;/note&gt; :::python python ~/dev/R/uavRst/inst/python/geotag_from_gpx.py.clean_task.gpx You are done with the preparation now. Time to start Photoscan.",
    "url": "http://localhost:4000/giswerk.org/docs/rs/micrors/agisoft/fixfootage/",
    "relUrl": "/docs/rs/micrors/agisoft/fixfootage/"
  },
  "4": {
    "id": "4",
    "title": "Home",
    "content": "Welcome to Giswerk Find ressources related to GIS, Remote Sensing and UAV",
    "url": "http://localhost:4000/giswerk.org/",
    "relUrl": "/"
  },
  "5": {
    "id": "5",
    "title": "",
    "content": "uavR packages Supported UAV platforms The reason using DJI is their absolute straightforward usage. Everybody can fly with a DJI but the price to pay off is a hermetically closed system. Only the litchi app provides additionally to a cloud based mission planer an offline/standalone interface that is up to date and facilitate the upload of a CSV formatted waypoint file to control autonomous flights with the the Phantom. The open uav community is focused on the PixHawk autopilot unit and the Mission Planner software. It is well documented and several APIs are provided. Nevertheless an affordable terrain following autonomous flight planning tool is not available yet. ‘‘makeFP’’ creates MAV format compliant mission files that are ready to upload to the Pixhawk controller using the ‘‘upload2Solo’’ function. The uavR Family The package family consists of 4 parts: flight planning ‘‘uavRmp’’ remote sensing ‘‘uavRrst’’ Up to now it has been dedicated to low budget rtf-UAVs as the DJI Phantom series and the 3DR Solo. However the current and future support will cover all Pixhawk based UAVs. uavRmp The open UAV community is focused on the PixHawk autopilot unit and the ‘‘MissionPlanner’’ or ‘‘APM Planner 2’’ software. Both are well documented and provide APIs and easy to use GUIs. Nevertheless they are missing planning capability (APM Planner) or an terrain following autonomous flight planning tool, that is also dealing with battery-dependent task splitting and save departures and approaches (MissionPlanner) yet. Other commercial competitors like the powerful ‘‘ugcs’’ software package are still lacking an advanced feature for generating smooth and save surface following flights for low AGL flights. The ‘‘uavRmd’’ package bridges this gap and generates ‘‘MAVLINK’’ format compliant mission files that can be uploaded to the Pixhawk controller using an integrated function or externally by any Ground Control Station software. The reason using DJI platforms is their absolute straightforward usage. Everybody can fly with a DJI but the price to pay off is a hermetically closed system. Only the litchi app provides additionally to a cloud based mission planer an offline/standalone interface that is up to date and facilitate the upload of a CSV formatted waypoint file to control autonomous flights with the the Phantom. The ‘’ uavRmp’’ package is hosted on CRAN and designed for UAV autonomous mission planning. In the first place it is a simple and open source planning tool for monitoring flights of low budget drones based on ‘‘R’’. It provide an easy workflow for planning autonomous surveys including battery-dependent task splitting and save departures and approaches of each monitoring chunks. It belongs to the uavR package family that provides more functionality for the pre- and post-processing as well as the analysis of the derived data. The core planning function ‘‘makeFP’’ (make flight plan) generates either intermediate flight control files for the DJI Phantom x UAVs or ready to upload control files for the Pixhawk/3DR Solo. The DJI control files are designed for using with the proprietary ‘‘Litchi’’ flight control app exchange format, while the 3DR Solo files are using the ‘‘MAVLINK’’ common message format, that is used by the PixHawk flight controller family. Please note that you will find on github the latest ‘’ uavRmp’’ release. uavRst The sister package ‘’ uavRst’’ is not hosted on CRAN yet. It makes heavy use of GRASS7, SAGA GIS, JS, Python OTB and some other CLI tools. The setup of the correct linkage to these APIs can be cumbersome. For using the uavRST package you need to install the ‘’ link2GI’’ package. Nevertheless all mentioned software packages have to be installed correctly on your the OS. It is just in parts tested under Windows but should run….The most easiest way to obtain a fairly good run time environment is to setup Linux as a dual boot system or in a VB. If interested in setting up a clean Xubuntu or Mint Linux and then use the post install script for installing most of the stuff. For using some of the the Solo related functions you need to install the dronekit python libs in addition. A full list of necessary libraries and binaries beyond R will soon be provided. Even if honestly working on it it will be still a long run passing the CRAN check, nevertheless it runs fine for now … Installation uavRmp :::rsplus # current CRAN version of the missionplanner install.packages(&quot;uavRmp&quot;) # latest github version devtools::install_github(&quot;gisma/uavRmp&quot;, ref = &quot;master&quot;) If you want to install all dependencies use: :::rsplus devtools::install_github(&quot;gisma/uavRmp&quot;, ref = &quot;master&quot;, dependencies = TRUE) Installation uavRmp :::rsplus # latest github version devtools::install_github(&quot;gisma/uavRst&quot;, ref = &quot;master&quot;) If you want to install all dependencies use: :::rsplus devtools::install_github(&quot;gisma/uavRst&quot;, ref = &quot;master&quot;, dependencies = TRUE) &lt;note important&gt;The package development is a work in progress and you will find more information on uavR gitbub pages. &lt;/note&gt;",
    "url": "http://localhost:4000/giswerk.org/docs/rs/micrors/uavr/intro/",
    "relUrl": "/docs/rs/micrors/uavr/intro/"
  },
  "6": {
    "id": "6",
    "title": "",
    "content": "Agisoft Photoscan Agisoft PhotoScan is a stand-alone software product that performs photogrammetric processing of digital images and generates 3D spatial data",
    "url": "http://localhost:4000/giswerk.org/docs/rs/micrors/agisoft/intro/",
    "relUrl": "/docs/rs/micrors/agisoft/intro/"
  },
  "7": {
    "id": "7",
    "title": "",
    "content": "DJI Phantom The winner takes it all… The Phantom series is just great extremely easy to fly with a pretty good camera and highly reliable. However it is a closed shop system with some real shortcomings with respect to survey and monitoring flights.",
    "url": "http://localhost:4000/giswerk.org/docs/rs/micrors/uavrs/dji/intro/",
    "relUrl": "/docs/rs/micrors/uavrs/dji/intro/"
  },
  "8": {
    "id": "8",
    "title": "",
    "content": "3DR Solo The 3DR Solo has been the most promising competitor of the DJI drones. Unfortunately the development and the hybris of the CEOs crashes the 3DR Company . So soon it won’t be available anymore. Nevertheless you will find here some usefull hints that my help as long as you operating a Solo if you are in trouble with your Solo. Groundstations There are several possibilities to fly a 3DR Solo or to manipulate the settings and flightplans. The most simple way is to use the Android based apps like ‘’ DroidPlanner 2’’ or the ‘‘Tower’’ App which provides an easy way to control the Solo parameters. Alternatively you may choose the ‘‘APM Planner 2.0’’ or the ‘‘Missionplanner’’. Both are powerful and highly reliable groundstations for the 3DR Solo as well as all Pixhawk based copters.",
    "url": "http://localhost:4000/giswerk.org/docs/rs/micrors/uavrs/3drsolo/intro/",
    "relUrl": "/docs/rs/micrors/uavrs/3drsolo/intro/"
  },
  "9": {
    "id": "9",
    "title": "",
    "content": "Low Budget Sensors Low cost but high tech UAVs have increased extremely the near earth remote sensing potential. A crucial thing is the payload in case of low budget drones usually a RGB and sometimes a NIR camera, A lot of them is ready to fly (rtf) fully assembled. Nevertheless it is also common practice to use personalized cameras and payload. Here we will focus on low budget RGB/NIR cameras.",
    "url": "http://localhost:4000/giswerk.org/docs/rs/micrors/sensors/intro/",
    "relUrl": "/docs/rs/micrors/sensors/intro/"
  },
  "10": {
    "id": "10",
    "title": "",
    "content": "Offline use of the Litchi mission hub The third party software Litchi provides an interface to the DJI Phantom and Inspire models. In addition to the typical derivatives like apps for android and ios and a cloud based tool Litchi provides an interface to user generated csv/kml waypoint flight control data. Unfortunately this website is heavily utilizing the Google map API which makes it fairly cumbersome to use it offline without a connection to the internet. A simple workaround using Google Chrome can overcome this shortcoming. Chrome offers the possibility to reload cached websites in a regular way. Depending on the Chrome version you use type chrome://flags in the address box and look for either ‘‘offline load stale’’ or ‘‘show saved copy’’ flag. You have to enable one of these options and restart the browser. If you navigate now offline to the litchi hub You will notice a new button that appear that lets you load the cached version. &lt;note important&gt;Don’t forget that you have visited the litchi hub start page with a working internet connection and preferably in your target area. If not there will be nothing cached what you might want to use when you are sitting offline in the woods.&lt;/note&gt;",
    "url": "http://localhost:4000/giswerk.org/docs/rs/micrors/uavrs/dji/litchihub/",
    "relUrl": "/docs/rs/micrors/uavrs/dji/litchihub/"
  },
  "11": {
    "id": "11",
    "title": "",
    "content": "Magnetic Interferences Besides the poor GPS antenna the ‘‘magnetic interferences’’ is an central issue of the 3DR Solo that can drive you crazy. Sometimes the compass is disturbed by metal etc. However in case of receiving all the times the error message ‘‘magnetic interferences’’ it is in most cases an parameter setup failure that is probably caused by a firmware update or a failure using external flight control software. In this case set the parameter ‘‘SYSID_SW_MREV’’ to ‘‘0’’. After doing so re-calibrate the sensors and it should work.",
    "url": "http://localhost:4000/giswerk.org/docs/rs/micrors/uavrs/3drsolo/magnetic/",
    "relUrl": "/docs/rs/micrors/uavrs/3drsolo/magnetic/"
  },
  "12": {
    "id": "12",
    "title": "",
    "content": "MAPIR Survey 2 Peau Production offers some useful stuff around micro uav camera equipment. The MAPIR cameras are fairly cheap converted action cams most probably a re branded Gitup cam. Unfortunately it comes along without activated WiFi but with a new lens and calibrated filter options for 6 different wavelength bands. Basic setup instructions Basically all of the cams can be set up in a similar way. The camera has three buttons. power ‘‘P’’, menu ‘‘M’’ (WiFi) and the trigger ‘‘T’’ button. All settings can be reached by this three buttons. The default settings as provided by Peau Productions are fairly OK if you fly under good illumination conditions. For autonomous flights You need to set the time lapse rate of the camera: Power on the camera ‘‘P’’, press ‘‘M’’, press 3 times ‘‘P’’ again and use the ‘‘T’’ button to change time lapse to 0.5 sec. Pre-flight setup instructions Before using the MAPIR cams please check the above settings. Next step is to synchronize the time settings as similar as possible with the GPS derived time. In the field you may use an app providing you the GPS time. For now you can use the page of the time-nuts tvb LeapSecond.com as embedded below. &lt;html&gt;&lt;iframe src=&quot;http://www.leapsecond.com/java/gpsclock.htm&quot; frameborder=&quot;0&quot; width=750 height=&quot;180&quot; allowfullscreen=&quot;true&quot; mozallowfullscreen=&quot;true&quot; webkitallowfullscreen=&quot;true&quot;&gt;&lt;/iframe&gt;&lt;/html&gt; Please do as follow: Power on the camera ‘‘P’’, then press again ‘‘P’’ four times until you see the system settings screen. Press the trigger button ‘‘T’’ then press 8 times ‘‘P’’ until you activate the time and date settings. Press ‘‘T’’ again for navigating to the appropriate date and time parameter. Usually you need to fix the seconds only. Set the time 10 seconds or so to the future of the current GPS time. You can change the settings with the ‘‘P’’ button. When the GPS time is reaching the preset camera time press 2 times the ‘‘M’’ button. This is the most exact (about 1 sec) manually way to fix the time to GPS. You have to to so with all cameras at least once a week. Basic survey settings Even if it strongly depends on the illumination and weather conditions You will find here some thumb rules. First Survey flight From this survey, you typically get Dense Point Clouds, DEMs, DSMs, NDVI data, Orthoimagery that means NIR or RGB images, which are the originally stitched images. Method You have to fly in an autonomous mode called task or mission flying over the target area and taking regularly pictures of the ground as you fly by. The photos must have an overlap in both directions. By having this overlap and side lap e.g. Agisoft Photoscan is able to align the photos. Recommended Parameters Ground Speed (aircraft speed): 20 km/h Above Ground Altitude (AGL): 100m Pattern: striped pattern Survey Grid Angle: If windy, perpendicular to wind direction. If no wind, optimized for least switchbacks. Photo sidelap: 80% Photo overlap: 80% (set camera to the minimaltime lapse at least a photo every 5 seconds). You may increase the overlap up to 90% but then you have to fly slower or increase the rate of pictures that are taken. Survey Grid Area: at least 50 meters beyond each side of the target survey area. Near surface flight From this type of survey, you typically will get high resolution dense point clouds, micro-relief DEMs, DSMs, and all products in a resolution of about one cm/pixel. Method You fly an autonomous mission over the target area and taking regularly pictures of the ground. The photos must have an higher overlap in both directions than during the basic task. Recommended Parameters Ground Speed (aircraft speed): 5-10 km/h Above Ground Altitude AGL: below 50m NOTE: ground means surface! Pattern: striped pattern Survey Grid Angle: If windy, perpendicular to wind direction. If no wind, optimized for least switchbacks. Photo sidelap: 90% Photo overlap: 90% (set camera to the minimal time lapse at least a photo every 5 seconds). Survey Grid Area: at least 20 meters beyond each side of the target survey area.",
    "url": "http://localhost:4000/giswerk.org/docs/rs/micrors/sensors/mapir/",
    "relUrl": "/docs/rs/micrors/sensors/mapir/"
  },
  "13": {
    "id": "13",
    "title": "",
    "content": "Setup Nvidia GPUs for Agisoft After a long run finally here is one successful solution for setting up consumer GPUs from Nvidia for a use with Agisoft. A lot of it is compiled on abhay’s blog. The following solution worked for a workstation server with Titan-X devices: :::bash # not sure if necessary but finally sucessful sudo apt-get install mesa-common-dev-lts-xenial sudo apt-get install mesa-common-dev sudo apt-get install mesa-common sudo apt-get install libssl1.0.0 sudo apt-get install libtxc-dxtn-s2tc-bin sudo apt-get install --reinstall xserver-xorg-video-intel libgl1-mesa-glx libgl1-mesa-dri xserver-xorg-core sudo apt-get install freeglut3-dev :::bash sudo nano /etc/modprobe.d/blacklist.conf blacklist amd76x_edac blacklist vga16gb blacklist nouveau blacklist rivafb blacklist nvidiafb blacklist rivatv # open a bash terminal as root sudo bash # remove existing nvidia stuff apt-get purge nvidia-* apt autoremove # 1st reboot shutdown -r now # remove remains of nvidia stuff # login as root sudo bash apt-get remove --purge nvidia* dpkg --configure -a # 2nd reboot shutdown -r now # login as root sudo bash # if so stop the GUI service lightdm stop # stop the X-server if so killall xinit # download the latest nvidia drivers. for titan-x currently NVIDIA-Linux-x86_64-367.44.run was the latest cd ~/Downloads/ wget us.download.nvidia.com/XFree86/Linux-x86_64/367.35/NVIDIA-Linux-x86_64-367.35.run # make the downloaded file an executable and run the NVidia installer chmod +x NVIDIA-Linux-x86_64-367.35.run ./NVIDIA-Linux-x86_64-367.35.run # follow the prompts in the process # once the process is over, reboot shutdown -r now Done",
    "url": "http://localhost:4000/giswerk.org/docs/rs/micrors/agisoft/nvidia/",
    "relUrl": "/docs/rs/micrors/agisoft/nvidia/"
  },
  "14": {
    "id": "14",
    "title": "",
    "content": "Optimize Alignment: How to align and merge Chunks It happens sometimes that not all pictures can be aligned. First, you can try to solve this situation by choosing different Alignment parameters, i.e. higher (or lower!) quality, or by adding georeference to the pictures (this way the Reference Preselection can be used). If this does not improve the result there is another method to get the not aligned pictures into the point cloud model. In general, you have to manually select the not aligned pictures in the point cloud model, move them into a new chunk, align them separately and then move them back into the main chunk and merge them into the point could. Usually the not aligned pictures occur in groups so you can select a whole area using the selection tool. Most likely there are pictures around the unaligned areas that have been aligned. It is very important to include a reasonable amount of these aligned pictures (at least all neighboring pictures) into the selection. These additional pictures are later used to re-integrate the newly aligned segment into the main point cloud. Re-integration is done in two steps: First, the two (or more) chunks are aligned and afterwards merged into one final chunk. Because of the necessary procedure (see work flow below) this will lead to a larger number of pictures in the main chunk. But the aim to have a more consistent and complete point cloud works quite well. Surplus pictures in the main chunk can be removed. If the alignment does not improve enough you can still move a part of the not aligned pictures from the first separated chunk to another sub-set chunk. (NOTE: remember to align and merge the chunks “upwards” in the reverse direction you reduced them in the “downwards” selecting process.) General workflow Duplicate chunk Activate duplicated chunk and select not aligned pictures by using the selection tool including aligned pictures around them (work in the model window, not in the picture list!) Inverse selection and delete pictures (in the picture list!). The result should be a chunk with the not aligned pictures surrounded by some aligned pictures Delete the Tie Points in the new chunk. (Note: You can still see how many pictures were originally aligned. Remember this number to check if the new alignment improves the situation.) Align pictures in the new chunk, use the same parameters as before and adapt them if the results are not satisfying Now all chunks will be combined, first by aligning them. Use “Align Chunks” in the Workflow Menu. Here you can set parameters for the alignment similar to the picture alignment. Parameters for the best results depend on the situation of the pictures. [A good try: Method = Point based, Accuracy = Medium, Point Limit = 0]. Finally merge the chunks. [Choose only those chunks you need, leave out “working chunks”!] Optional, the surplus (double) pictures can be removed to lower project file size. References for alignment optimizing: http://www.agisoft.com/pdf/photoscan-pro_1_3_en.pdf http://www.agisoft.com/forum/index.php?topic=6995.0 http://www.agisoft.com/forum/index.php?topic=148.0 Agisoft Tutorial: Marker based chunk alignment http://www.agisoft.com/forum/index.php?topic=381.0",
    "url": "http://localhost:4000/giswerk.org/docs/rs/micrors/agisoft/optimizealigment/",
    "relUrl": "/docs/rs/micrors/agisoft/optimizealigment/"
  },
  "15": {
    "id": "15",
    "title": "",
    "content": "Mission flights parameters If you want to avoid return to launch actions of the Solo during mission tasks you have to change some parameters of the Solo parameter setup. Basically you have to deal with the ‘‘Geofence’’ and the ‘‘Failsafe’’ settings while flying the Solo in the ‘‘AUTO’’ mode. &lt;note warning&gt;Please be very very careful. The below changes bypass some central safety issues of the UAV. Please read all additional information. the settings are tested for the Solo only! Take care and reset them for normal flight modes&lt;/note&gt; Geofence You will find a comprhensive explanation at the embedded help page of ArduPilot. Please follow the instructions while setting the Geofence. For mission flights in ‘‘AUTO’’ mode you should deactivate it. Please find more information at Geofence . Failsafe Actions There are several failsafe mechanisms to ease vehicle recovery/prevent wandering in the event that vehicle control is lost. The following are crucial for mission tasks. Ground Control Station failsave The Ground Control Station ‘‘GCS’’ failsafe controls how copter will behave if contact with the GCS is lost. Depending on the setting and vehicle position the failsafe will either RTL/LAND, or continue an active mission.You need the latter. Set the ‘‘FS_GCS_ENABLE’’ parameter to ‘‘Enabled Continue with Mission in Auto Mode’’ Please find more information at GCS Failsafe. Radio Failsafe Copter supports Return-To-Launch in cases where contact between the Pilot’s RC transmitter and the flight controller’s receiver is lost. Note the ‘‘Radio failsafe’’ is also called ‘‘Throttle failsafe’’. Set the ‘‘FS_THR_ENABLE’’ parameter to ‘‘Enabled Continue with Mission in Auto Mode’’. Please find more information at RC Failsafe. Battery Failsafe The battery failsafe can be set-up to automatically trigger an RTL or LAND when the vehicle battery voltage or estimated remaining power has crossed a configurable threshold. Set the ‘‘FS_BATT_ENABLE’’ to ‘‘RTL’’. Please find more information at Battery Failsafe. &lt;note important&gt;The below Solo parameter file comes with ABSOLUTELY NO GUARANTEE. Please check it! You may copy and save it as an common ASCII file. You can upload it to the Solo flight controller using e.g. the ‘‘Tower’’ App. ** Please calibrate the Solo sensors after uploading the new parameters to avoid strange behaviors** &lt;/note&gt; :::bash #NOTE: 3DR Solo param list for mission flights ACCEL_Z_D , 0.000000 ACCEL_Z_FILT_HZ , 20.000000 ACCEL_Z_I , 1.500000 ACCEL_Z_IMAX , 800.000000 ACCEL_Z_P , 0.750000 ACRO_BAL_PITCH , 1.000000 ACRO_BAL_ROLL , 1.000000 ACRO_EXPO , 0.300000 ACRO_RP_P , 4.000000 ACRO_TRAINER , 2.000000 ACRO_YAW_P , 1.000000 AHRS_COMP_BETA , 0.100000 AHRS_GPS_GAIN , 1.000000 AHRS_GPS_MINSATS , 6.000000 AHRS_GPS_USE , 1.000000 AHRS_ORIENTATION , 12.000000 AHRS_RP_P , 0.200000 AHRS_TRIM_X , 0.001836 AHRS_TRIM_Y , -0.004283 AHRS_TRIM_Z , 0.000000 AHRS_WIND_MAX , 0.000000 AHRS_YAW_P , 0.200000 ANGLE_MAX , 2000.000000 ARMING_CHECK , -1.000000 ATC_ACCEL_P_MAX , 36000.000000 ATC_ACCEL_R_MAX , 36000.000000 ATC_ACCEL_Y_MAX , 7000.000000 ATC_LEAD_PIT_R , 1.000000 ATC_LEAD_PIT_W , 0.000000 ATC_LEAD_RLL_R , 4.000000 ATC_LEAD_RLL_W , 15.000000 ATC_RATE_FF_ENAB , 1.000000 ATC_SLEW_YAW , 1000.000000 AUTOTUNE_AGGR , 0.100000 AUTOTUNE_AXES , 7.000000 BATT2_AMP_OFFSET , 0.000000 BATT2_AMP_PERVOL , 17.000000 BATT2_CAPACITY , 3300.000000 BATT2_CURR_PIN , 3.000000 BATT2_MONITOR , 0.000000 BATT2_VOLT_MULT , 10.100000 BATT2_VOLT_PIN , 2.000000 BATT_AMP_OFFSET , 0.000000 BATT_AMP_PERVOLT , 17.000000 BATT_CAPACITY , 5200.000000 BATT_CURR_PIN , 3.000000 BATT_MONITOR , 5.000000 BATT_VOLT_MULT , 10.100000 BATT_VOLT_PIN , 2.000000 BRD_PWM_COUNT , 4.000000 BRD_SAFETYENABLE , 0.000000 BRD_SBUS_OUT , 0.000000 BRD_SER1_RTSCTS , 1.000000 BRD_SER2_RTSCTS , 2.000000 CAM_DURATION , 10.000000 CAM_SERVO_OFF , 1100.000000 CAM_SERVO_ON , 1300.000000 CAM_TRIGG_DIST , 0.000000 CAM_TRIGG_TYPE , 0.000000 CH10_OPT , 0.000000 CH11_OPT , 0.000000 CH12_OPT , 0.000000 CH7_OPT , 0.000000 CH8_OPT , 0.000000 CH9_OPT , 0.000000 CHUTE_ALT_MIN , 10.000000 CHUTE_ENABLED , 0.000000 CHUTE_SERVO_OFF , 1100.000000 CHUTE_SERVO_ON , 1300.000000 CHUTE_TYPE , 10.000000 CIRCLE_RADIUS , 1000.000000 CIRCLE_RATE , 20.000000 CLI_ENABLED , 0.000000 COMPASS_AUTODEC , 1.000000 COMPASS_DEC , 0.013086 COMPASS_DEV_ID , 73225.000000 COMPASS_DEV_ID2 , 131874.000000 COMPASS_DEV_ID3 , 66826.000000 COMPASS_DIA2_X , 1.005852 COMPASS_DIA2_Y , 0.998313 COMPASS_DIA2_Z , 1.001465 COMPASS_DIA3_X , 1.000000 COMPASS_DIA3_Y , 1.000000 COMPASS_DIA3_Z , 1.000000 COMPASS_DIA_X , 1.000000 COMPASS_DIA_Y , 1.000000 COMPASS_DIA_Z , 1.000000 COMPASS_EXTERN2 , 0.000000 COMPASS_EXTERN3 , 0.000000 COMPASS_EXTERNAL , 1.000000 COMPASS_LEARN , 0.000000 COMPASS_MOT2_X , 0.000000 COMPASS_MOT2_Y , 0.000000 COMPASS_MOT2_Z , 0.000000 COMPASS_MOT3_X , 0.000000 COMPASS_MOT3_Y , 0.000000 COMPASS_MOT3_Z , 0.000000 COMPASS_MOTCT , 0.000000 COMPASS_MOT_X , 0.000000 COMPASS_MOT_Y , 0.000000 COMPASS_MOT_Z , 0.000000 COMPASS_ODI2_X , -0.025515 COMPASS_ODI2_Y , 0.009890 COMPASS_ODI2_Z , -0.002426 COMPASS_ODI3_X , 0.000000 COMPASS_ODI3_Y , 0.000000 COMPASS_ODI3_Z , 0.000000 COMPASS_ODI_X , 0.000000 COMPASS_ODI_Y , 0.000000 COMPASS_ODI_Z , 0.000000 COMPASS_OFS2_X , 104.959915 COMPASS_OFS2_Y , 4.826456 COMPASS_OFS2_Z , 227.189728 COMPASS_OFS3_X , 0.000000 COMPASS_OFS3_Y , 0.000000 COMPASS_OFS3_Z , 0.000000 COMPASS_OFS_X , 1.842019 COMPASS_OFS_Y , -47.684803 COMPASS_OFS_Z , -109.906815 COMPASS_ORIENT , 38.000000 COMPASS_ORIENT2 , 0.000000 COMPASS_ORIENT3 , 0.000000 COMPASS_PRIMARY , 0.000000 COMPASS_USE , 1.000000 COMPASS_USE2 , 1.000000 COMPASS_USE3 , 0.000000 EKF_ABIAS_PNOISE , 0.000050 EKF_ACC_PNOISE , 0.250000 EKF_ALT_NOISE , 2.000000 EKF_ALT_SOURCE , 1.000000 EKF_EAS_GATE , 10.000000 EKF_EAS_NOISE , 1.400000 EKF_FALLBACK , 1.000000 EKF_FLOW_DELAY , 10.000000 EKF_FLOW_GATE , 3.000000 EKF_FLOW_NOISE , 0.250000 EKF_GBIAS_PNOISE , 0.000001 EKF_GLITCH_ACCEL , 100.000000 EKF_GLITCH_RAD , 25.000000 EKF_GND_GRADIENT , 2.000000 EKF_GPS_CHECK , 127.000000 EKF_GPS_LIM_HDFT , 0.300000 EKF_GPS_LIM_HDOP , 240.000000 EKF_GPS_LIM_HERR , 5.000000 EKF_GPS_LIM_HSPD , 0.300000 EKF_GPS_LIM_NSAT , 6.000000 EKF_GPS_LIM_SERR , 1.000000 EKF_GPS_LIM_VSPD , 0.300000 EKF_GPS_TYPE , 0.000000 EKF_GYRO_PNOISE , 0.015000 EKF_HGT_GATE , 10.000000 EKF_MAGB_PNOISE , 0.000600 EKF_MAGE_PNOISE , 0.000600 EKF_MAG_CAL , 3.000000 EKF_MAG_GATE , 3.000000 EKF_MAG_NOISE , 0.050000 EKF_MAX_FLOW , 2.500000 EKF_POSNE_NOISE , 0.500000 EKF_POS_DELAY , 200.000000 EKF_POS_GATE , 5.000000 EKF_RNG_GATE , 5.000000 EKF_VELD_NOISE , 0.700000 EKF_VELNE_NOISE , 0.500000 EKF_VEL_DELAY , 200.000000 EKF_VEL_GATE , 4.000000 EKF_WIND_PNOISE , 0.100000 EKF_WIND_PSCALE , 0.500000 EPM_ENABLE , 0.000000 EPM_GRAB , 1900.000000 EPM_NEUTRAL , 1500.000000 EPM_REGRAB , 0.000000 EPM_RELEASE , 1100.000000 ESC , 0.000000 FENCE_ACTION , 0.000000 FENCE_ALT_MAX , 150.000000 FENCE_ENABLE , 0.000000 FENCE_MARGIN , 0.000000 FENCE_RADIUS , 1000.000000 FENCE_TYPE , 0.000000 FLOW_ENABLE , 0.000000 FLOW_FXSCALER , 0.000000 FLOW_FYSCALER , 0.000000 FLOW_ORIENT_YAW , 0.000000 FLTMODE1 , 3.000000 FLTMODE2 , 5.000000 FLTMODE3 , 5.000000 FLTMODE4 , 5.000000 FLTMODE5 , 5.000000 FLTMODE6 , 5.000000 FRAME , 1.000000 FS_BATT_CURR_RTL , 0.000000 FS_BATT_ENABLE , 2.000000 FS_BATT_MAH , 520.000000 FS_BATT_VOLTAGE , 14.000000 FS_EKF_ACTION , 2.000000 FS_EKF_THRESH , 0.800000 FS_GCS_ENABLE , 2.000000 FS_THR_ENABLE , 2.000000 FS_THR_VALUE , 910.000000 GND_ABS_PRESS , 99230.187500 GND_ALT_OFFSET , 0.000000 GND_TEMP , 25.481892 GPS_AUTO_SWITCH , 1.000000 GPS_INJECT_TO , 127.000000 GPS_MIN_DGPS , 100.000000 GPS_MIN_ELEV , -100.000000 GPS_NAVFILTER , 6.000000 GPS_SBAS_MODE , 2.000000 GPS_SBP_LOGMASK , -256.000000 GPS_TYPE , 2.000000 GPS_TYPE2 , 0.000000 INS_ACC2OFFS_X , 0.258221 INS_ACC2OFFS_Y , -0.185451 INS_ACC2OFFS_Z , 0.962418 INS_ACC2SCAL_X , 1.006014 INS_ACC2SCAL_Y , 1.020488 INS_ACC2SCAL_Z , 1.019468 INS_ACC3OFFS_X , 0.059465 INS_ACC3OFFS_Y , -0.137146 INS_ACC3OFFS_Z , 0.424939 INS_ACC3SCAL_X , 0.991695 INS_ACC3SCAL_Y , 1.004397 INS_ACC3SCAL_Z , 0.981133 INS_ACCEL_FILTER , 20.000000 INS_ACCOFFS_X , -0.141785 INS_ACCOFFS_Y , 0.158582 INS_ACCOFFS_Z , -0.008771 INS_ACCSCAL_X , 0.999281 INS_ACCSCAL_Y , 0.999493 INS_ACCSCAL_Z , 0.985837 INS_GYR2OFFS_X , 0.001365 INS_GYR2OFFS_Y , 0.020204 INS_GYR2OFFS_Z , -0.007679 INS_GYR3OFFS_X , -0.001679 INS_GYR3OFFS_Y , -0.005535 INS_GYR3OFFS_Z , 0.039744 INS_GYROFFS_X , -0.016689 INS_GYROFFS_Y , -0.042669 INS_GYROFFS_Z , -0.011869 INS_GYRO_FILTER , 20.000000 INS_PRODUCT_ID , 5.000000 LAND_REPOSITION , 1.000000 LAND_SPEED , 50.000000 LGR_SERVO_DEPLOY , 1750.000000 LGR_SERVO_RTRACT , 1250.000000 LOG_BACKEND_TYPE , 3.000000 LOG_BITMASK , 131070.000000 MAG_ENABLE , 1.000000 MIS_RESTART , 0.000000 MIS_TOTAL , 172.000000 MNT_ANGMAX_PAN , 4500.000000 MNT_ANGMAX_ROL , 4500.000000 MNT_ANGMAX_TIL , 0.000000 MNT_ANGMIN_PAN , -4500.000000 MNT_ANGMIN_ROL , -4500.000000 MNT_ANGMIN_TIL , -9000.000000 MNT_DEFLT_MODE , 3.000000 MNT_JSTICK_SPD , 0.000000 MNT_LEAD_PTCH , 0.000000 MNT_LEAD_RLL , 0.000000 MNT_NEUTRAL_X , 0.000000 MNT_NEUTRAL_Y , 0.000000 MNT_NEUTRAL_Z , 0.000000 MNT_RC_IN_PAN , 0.000000 MNT_RC_IN_ROLL , 0.000000 MNT_RC_IN_TILT , 6.000000 MNT_RETRACT_X , 0.000000 MNT_RETRACT_Y , 0.000000 MNT_RETRACT_Z , 0.000000 MNT_STAB_PAN , 1.000000 MNT_STAB_ROLL , 1.000000 MNT_STAB_TILT , 1.000000 MNT_TYPE , 2.000000 MOT_CURR_MAX , 42.000000 MOT_SPIN_ARMED , 75.000000 MOT_THR_MIX_MIN , 0.150000 MOT_THST_BAT_MAX , 16.799999 MOT_THST_BAT_MIN , 12.000000 MOT_THST_EXPO , 0.800000 MOT_THST_MAX , 0.940000 MOT_YAW_HEADROOM , 200.000000 PHLD_BRAKE_ANGLE , 3000.000000 PHLD_BRAKE_RATE , 8.000000 PILOT_ACCEL_Z , 100.000000 PILOT_THR_BHV , 1.000000 PILOT_THR_FILT , 2.000000 PILOT_TKOFF_ALT , 75.000000 PILOT_TKOFF_DZ , 250.000000 PILOT_VELZ_MAX , 133.000000 POS_XY_P , 0.700000 POS_Z_P , 1.000000 PSC_ACC_XY_FILT , 2.000000 RALLY_LIMIT_KM , 0.000000 RALLY_TOTAL , 0.000000 RATE_PIT_D , 0.008000 RATE_PIT_FILT_HZ , 40.000000 RATE_PIT_I , 0.168000 RATE_PIT_IMAX , 3000.000000 RATE_PIT_P , 0.168000 RATE_RLL_D , 0.007200 RATE_RLL_FILT_HZ , 40.000000 RATE_RLL_I , 0.116000 RATE_RLL_IMAX , 3000.000000 RATE_RLL_P , 0.116000 RATE_YAW_D , 0.000000 RATE_YAW_FILT_HZ , 7.600000 RATE_YAW_I , 0.066000 RATE_YAW_IMAX , 1000.000000 RATE_YAW_P , 0.660000 RC10_DZ , 0.000000 RC10_FUNCTION , 0.000000 RC10_MAX , 1900.000000 RC10_MIN , 1100.000000 RC10_REV , 1.000000 RC10_TRIM , 1500.000000 RC11_DZ , 0.000000 RC11_FUNCTION , 0.000000 RC11_MAX , 1900.000000 RC11_MIN , 1100.000000 RC11_REV , 1.000000 RC11_TRIM , 1500.000000 RC12_DZ , 0.000000 RC12_FUNCTION , 0.000000 RC12_MAX , 1900.000000 RC12_MIN , 1100.000000 RC12_REV , 1.000000 RC12_TRIM , 1500.000000 RC13_DZ , 0.000000 RC13_FUNCTION , 0.000000 RC13_MAX , 1900.000000 RC13_MIN , 1100.000000 RC13_REV , 1.000000 RC13_TRIM , 1500.000000 RC14_DZ , 0.000000 RC14_FUNCTION , 0.000000 RC14_MAX , 1900.000000 RC14_MIN , 1100.000000 RC14_REV , 1.000000 RC14_TRIM , 1500.000000 RC1_DZ , 10.000000 RC1_MAX , 2000.000000 RC1_MIN , 1000.000000 RC1_REV , 1.000000 RC1_TRIM , 1500.000000 RC2_DZ , 10.000000 RC2_MAX , 2000.000000 RC2_MIN , 1000.000000 RC2_REV , 1.000000 RC2_TRIM , 1500.000000 RC3_DZ , 30.000000 RC3_MAX , 1900.000000 RC3_MIN , 1000.000000 RC3_REV , 1.000000 RC3_TRIM , 1500.000000 RC4_DZ , 10.000000 RC4_MAX , 2000.000000 RC4_MIN , 1000.000000 RC4_REV , 1.000000 RC4_TRIM , 1500.000000 RC5_DZ , 0.000000 RC5_FUNCTION , 0.000000 RC5_MAX , 1900.000000 RC5_MIN , 1100.000000 RC5_REV , 1.000000 RC5_TRIM , 1500.000000 RC6_DZ , 0.000000 RC6_FUNCTION , 0.000000 RC6_MAX , 1520.000000 RC6_MIN , 1000.000000 RC6_REV , 1.000000 RC6_TRIM , 1000.000000 RC7_DZ , 0.000000 RC7_FUNCTION , 0.000000 RC7_MAX , 1900.000000 RC7_MIN , 1100.000000 RC7_REV , 1.000000 RC7_TRIM , 1500.000000 RC8_DZ , 0.000000 RC8_FUNCTION , 0.000000 RC8_MAX , 1900.000000 RC8_MIN , 1100.000000 RC8_REV , 1.000000 RC8_TRIM , 1500.000000 RC9_DZ , 0.000000 RC9_FUNCTION , 0.000000 RC9_MAX , 1900.000000 RC9_MIN , 1100.000000 RC9_REV , 1.000000 RC9_TRIM , 1500.000000 RCMAP_PITCH , 2.000000 RCMAP_ROLL , 1.000000 RCMAP_THROTTLE , 3.000000 RCMAP_YAW , 4.000000 RC_FEEL_RP , 20.000000 RC_SPEED , 490.000000 RELAY_DEFAULT , 0.000000 RELAY_PIN , 54.000000 RELAY_PIN2 , 55.000000 RELAY_PIN3 , -1.000000 RELAY_PIN4 , -1.000000 RNGFND2_FUNCTION , 0.000000 RNGFND2_GNDCLEAR , 10.000000 RNGFND2_MAX_CM , 700.000000 RNGFND2_MIN_CM , 20.000000 RNGFND2_OFFSET , 0.000000 RNGFND2_PIN , -1.000000 RNGFND2_RMETRIC , 1.000000 RNGFND2_SCALING , 3.000000 RNGFND2_SETTLE , 0.000000 RNGFND2_STOP_PIN , -1.000000 RNGFND2_TYPE , 0.000000 RNGFND_FUNCTION , 0.000000 RNGFND_GAIN , 0.800000 RNGFND_GNDCLEAR , 10.000000 RNGFND_MAX_CM , 700.000000 RNGFND_MIN_CM , 20.000000 RNGFND_OFFSET , 0.000000 RNGFND_PIN , -1.000000 RNGFND_PWRRNG , 0.000000 RNGFND_RMETRIC , 1.000000 RNGFND_SCALING , 3.000000 RNGFND_SETTLE , 0.000000 RNGFND_STOP_PIN , -1.000000 RNGFND_TYPE , 0.000000 RSSI_PIN , -1.000000 RSSI_RANGE , 5.000000 RTL_ALT , 10000.000000 RTL_ALT_FINAL , 0.000000 RTL_CLIMB_MIN , 1000.000000 RTL_CONE_SLOPE , 3.000000 RTL_LOIT_TIME , 0.000000 RTL_SPEED , 1000.000000 SCHED_DEBUG , 0.000000 SERIAL0_BAUD , 115.000000 SERIAL1_BAUD , 921.000000 SERIAL1_PROTOCOL , 1.000000 SERIAL2_BAUD , 57.000000 SERIAL2_PROTOCOL , 0.000000 SERIAL3_BAUD , 38.000000 SERIAL3_PROTOCOL , 5.000000 SERIAL4_BAUD , 230.000000 SERIAL4_PROTOCOL , 1.000000 SIMPLE , 0.000000 SR0_EXTRA1 , 0.000000 SR0_EXTRA2 , 0.000000 SR0_EXTRA3 , 0.000000 SR0_EXT_STAT , 0.000000 SR0_PARAMS , 0.000000 SR0_POSITION , 0.000000 SR0_RAW_CTRL , 0.000000 SR0_RAW_SENS , 0.000000 SR0_RC_CHAN , 0.000000 SR1_EXTRA1 , 4.000000 SR1_EXTRA2 , 4.000000 SR1_EXTRA3 , 2.000000 SR1_EXT_STAT , 2.000000 SR1_PARAMS , 10.000000 SR1_POSITION , 2.000000 SR1_RAW_CTRL , 3.000000 SR1_RAW_SENS , 2.000000 SR1_RC_CHAN , 2.000000 SR2_EXTRA1 , 0.000000 SR2_EXTRA2 , 0.000000 SR2_EXTRA3 , 0.000000 SR2_EXT_STAT , 0.000000 SR2_PARAMS , 0.000000 SR2_POSITION , 0.000000 SR2_RAW_CTRL , 0.000000 SR2_RAW_SENS , 0.000000 SR2_RC_CHAN , 0.000000 STB_PIT_P , 8.000000 STB_RLL_P , 9.500000 STB_YAW_P , 7.000000 SUPER_SIMPLE , 0.000000 SYSID_MYGCS , 255.000000 SYSID_SW_MREV , 120.000000 SYSID_SW_TYPE , 10.000000 SYSID_THISMAV , 1.000000 TELEM_DELAY , 0.000000 TERRAIN_ENABLE , 1.000000 TERRAIN_SPACING , 100.000000 THR_DZ , 10.000000 THR_MID , 400.000000 THR_MIN , 130.000000 TUNE , 0.000000 TUNE_HIGH , 1000.000000 TUNE_LOW , 0.000000 VEL_XY_FILT_HZ , 5.000000 VEL_XY_I , 0.500000 VEL_XY_IMAX , 1000.000000 VEL_XY_P , 1.400000 VEL_Z_P , 5.000000 WPNAV_ACCEL , 340.000000 WPNAV_ACCEL_Z , 160.000000 WPNAV_LOIT_JERK , 1000.000000 WPNAV_LOIT_MAXA , 229.000000 WPNAV_LOIT_MINA , 108.000000 WPNAV_LOIT_SPEED , 500.000000 WPNAV_RADIUS , 3000.000000 WPNAV_SPEED , 1100.000000 WPNAV_SPEED_DN , 240.000000 WPNAV_SPEED_UP , 320.000000 WP_YAW_BEHAVIOR , 0.000000",
    "url": "http://localhost:4000/giswerk.org/docs/rs/micrors/uavrs/3drsolo/paramsetting/",
    "relUrl": "/docs/rs/micrors/uavrs/3drsolo/paramsetting/"
  },
  "16": {
    "id": "16",
    "title": "",
    "content": "Setup Photoscan on a cluster The concept is roughly outlined in chapter 8 of the Agisoft Photoscan manual. Nevertheless there atre some pitfalls and not so well documented features. First you need to export a common net ressource. You may follow the [[https://www.digitalocean.com/community/tutorials/how-to-set-up-an-nfs-mount-on-ubuntu-16-04 | digitialocean]] example: | ———————— :::bash # on the sever side (exporting machine) sudo apt-get install nfs-kernel-server sudo mkdir /var/nfs/general -p sudo chown nobody:nogroup /var/nfs/general sudo nano /etc/exports /var/nfs/general xxx.xxx.xxx.xxx(rw,sync,no_subtree_check) sudo systemctl restart nfs-kernel-server # on the clients side sudo apt-get install nfs-common sudo mkdir /var/nfs/agi -p sudo mount xxx.xxx.xxx.xxx:/var/nfs/general /var/nfs/agi Now you have to start a head node as photoscan server :::bash nohup ./photoscan.sh --server xxx.xxx.xxx.xxx --dispatch xxx.xxx.xxx.xxx --root /var/nfs/agi Next you may assign node(s) :::bash nohup ./photoscan.sh --node --dispatch xxx.xxx.xxx.xxx --opencl_gpu_mask 1 --root /var/nfs/agi &lt;note&gt; Be aware, that the monitor and the network installation of Agisoft Photoscan must have the same version. The installation on the computer can have a newer version. &lt;/note&gt;",
    "url": "http://localhost:4000/giswerk.org/docs/rs/micrors/agisoft/photoscancluster/",
    "relUrl": "/docs/rs/micrors/agisoft/photoscancluster/"
  },
  "17": {
    "id": "17",
    "title": "",
    "content": "Agisoft Photoscan basic workflow Even if both criteria not open source not free software, are missing one have to admit that Agisoft’s Photoscan is a great tool for deriving point clouds and all kind of surface models from plain RGB imagery. It comes along with an incredible straightforward GUI and in Question of hardware requests and cost eff ency it is well balanced. For a deeper insight one should know how to deal with a lot o settings. We will cover this on a more specialized article Photoscan and UAV Imagery. Let’s start to follow the white rabbit. Add the photos to Photoscan After loading the images into Agisofts Photoscan the aerial images are lining up along the flight track as you can see below. Alignment &lt;note important&gt;Note: The quality of the alignment is crucial for all follow up products - especially 3D dense point cloud models and the cration of the orthoimage&lt;/note&gt; The Align Images process is somehow exploitative. For a quick start it is a good practice to use the following settings: It will give you an good estimate how the general alignment process performs. &lt;note important&gt;Note: we did choose reference preselection due to the georeferenced images&lt;/note&gt; However there are a lot of different requirements depending on sensor, light and surface characteristics. For high quality images there is obviously no significant quality improvement if increasing the number of keypoints behind 240000. You may calculate as a rule of thumb (same post) the maximum number of keypoint according to megapixels x 6400. For the Mapir or DJI this will results in roughly 77000 keypoints. Nevertheless setting the params to zero will be interpreted as maximum which seems to be reliable if one is filtering the point clouds and 3D models in a second step. So a reasonable highest quality approach may look like: &lt;note tip&gt;Please keep in mind that it will take a really long time to align the images in a high quality process&lt;/note&gt; &lt;note important&gt;Please keep also in mind that if you have a poor image quality and/or alignment you will mess up your tie point cloud with a lot of spurious tie points if you use the maximum setting. It happens sometimes that you wont’ be able to get rid of these points later on.&lt;/note&gt; Creating high quality sparse (tie) point clouds The trick to derive a high quality sparse point clouds is to avoid spurious information and to retrieve a good spatial positioning of the images. In other words you need a optimal alignment with as less as possible “spurious” tie points. You can reach itin most cases with a highest quality alignment and posterior filtering and camera optimization process. If still the result is not satisfying your needs, you additionally may also use ground control points GCPs. We made fairly good experiences following jhutan who suggest the this workflow for generating high quality point clouds. Usually we need only one recursion of gradual selection: Remove sparse points by gradual selection (see below) Optimize cameras (after** each** removal) Optionally repeat steps 1-2 until the reconstruction error is minimized Ad 1: this removes spurious points from the point cloud e.g. it will smooth the surface Ad 2: all cameras will be re-optimized for the new geometry Gradual Selection Process Before starting the gradual selection process right-click your current chunk in the Workspace window and select “Duplicate chunk”, then proceed with the copy. Choose “Reconstruction uncertainty“. Type something like “10” and see the as a result all points in the sparse cloud selected Clicking “OK” and “DEL” will delete the selected points. If the DEL key doesn’t work, you need to click once into the model window to activate it, and press DEL again. Next choose the “Reprojection Error” option. Set it to &lt; 1 and again delete the selected points then click that wizard’s wand icon again. Finally check the “Projection Accuracy” try to delete the poorest 10 % of the points For more details have a look at e.g. dinosaurpaleo. &lt;note tip&gt;It is recommended to keep in line with this process if you want to reconstruct high quality point clouds and surfaces like textures or orthoimages. Even if it seems to be an annoying manual approach, you will soon notice that the time you have spent pays itself several times… For a first automatic retrieval you may use the script makeSparseCloud.py&lt;/note&gt; Build 3D model (mesh) Now you may use the derived sparse point cloud to build a 3D model. the process is straightforward. For an maximum number of faces in the mesh choose the following settings: Generate Orthophoto Creating an orthoimage is a very straightforward approach and it differs slightly from deriving a high density point cloud. Just follow the below outlined Workflow. load the prepared images check image quality align images according as proposed before build mesh on an optimized sparse point cloud create orthoimage on the mesh Using a mesh (3D model) will give in most cases better results for the orthoimage generation of low AGL flight level altitude imagery. Nevertheless you have to check what kind of cloud is more sufficient the dense or sparse point cloud. It depends on the structure. You will get often more satisfactory results using a well preprocessed sparse point cloud. So the recommended settings are: Et voila - Finally you derive an orthoimage of fairly high quality Creating high quality dense point clouds Hence micro-remote sensing is usually restricted to a single (visible) layer the temporal scale this layer can be observed by drones is the advantage compared to high-cost and temporal limited LIDAR data sets. Using photoscan the dense point cloud might still be classified in different layers depending of the structure of the observed area and structure (i.e a deciduous forest can be observed in winter for ground models and tree structure while summer flights will deliver good surface models). Additionally dense clouds can be exported in several formats to be used in further processing in QGIS, SAGa or 3D modelbuilder software. So it is easy to benefit from already existing and established workflows which were developed for LIDAR oder 3D modeling data. The settings of the dense point cloud calculation determines quality and necessary calculation time. Hereby a higher quality results in longer calculation time. Aggressive filtering ignores small structures and runs fastest while moderate and mild filtering consider smaller structures on the cost of longer calculation time. The dense point cloud can be calculated as soon the pictures are aligned. Even if the dense cloud comes second in the workflow dropdown menu in Photoscan it should be considered to calculate the orthoimage first as the dense point cloud will take the longest time of all processes. Photoscan import/export",
    "url": "http://localhost:4000/giswerk.org/docs/rs/micrors/agisoft/workflow/",
    "relUrl": "/docs/rs/micrors/agisoft/workflow/"
  }
  
}
